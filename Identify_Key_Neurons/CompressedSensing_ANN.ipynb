{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "'''Trains a simple network on the MNIST dataset to infer essential neurons for digit recognition.'''\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential, Model \nfrom keras.layers import Input, Dense, Lambda, Flatten\nfrom keras import backend as K\nimport numpy as np\nfrom keras import optimizers\nfrom keras import regularizers\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\nimport seaborn as sns"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "# %matplotlib notebook      #uncommment for interactive plotting"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# Data Pre-Processing\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\nnum_classes = 10\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n# less data\n## x_train = x_train[:15000]\n## x_test = x_test[:3000]\n## y_train = y_train[:15000]\n## y_test = y_test[:3000]\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "import pickle\n# Getting back the objects:\nwith open('../data/mnist_dataset.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n    x_train, x_test, y_train, y_test = pickle.load(f)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
      ],
      "source": "print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "## Neural Network Model and Training\n### ***Training might take quite a bit of time. You can scroll down and load already trained network for further analysis. For clearity, the neural network structure and training details cell kept below.***"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# # MODEL Network w/ regularization on activations\n\n# input_img = Input(shape=(784,))\n# x = Dense(100, activation='sigmoid',activity_regularizer=regularizers.l1(0.04))(input_img)\n# x = Dense(100, activation='sigmoid',activity_regularizer=regularizers.l1(0.04))(x)\n# x = Dense(100, activation='sigmoid',activity_regularizer=regularizers.l1(0.04))(x)\n# x = Dense(100, activation='sigmoid',activity_regularizer=regularizers.l1(0.04))(x)\n# output_class = Dense(10, activation='softmax')(x)\n\n# model = Model(input_img, output_class)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "#optimizer\n# model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# Training - manual\n# batch_size = 1\n# epochs = 30\n# model.fit(x_train, y_train,\n#           batch_size=batch_size,\n#           epochs=epochs,\n#           verbose=1,\n#           validation_data=(x_test, y_test))\n\n# score = model.evaluate(x_test, y_test, verbose=0)\n# print('Test loss:', score[0])\n# print('Test accuracy:', score[1])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# score = model.evaluate(x_test, y_test, verbose=1)\n# print('Test loss:', score[0])\n# print('Test accuracy:', score[1])\n# testacc = deepcopy(score[1])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "# model.save_weights('my_weights.model')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "# model.load_weights('my_weights.model')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "## SAVE MODEL\n# model.save('my_model.h5')"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "## Load Trained Network for Analysis"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# LOAD MODEL\nfrom keras.models import load_model\nmodel = load_model('../data/model_sparseFinal.h5')\nmodel.save_weights('my_weights.model')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "model.summary()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "score = model.evaluate(x_test, y_test, verbose=0)\ntestacc = deepcopy(score[1])\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "## Finding Key Neurons via Compressed Sensing"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Finding Ground Truth with Single Neuron Ablations"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# mutate single neuron each time by assigning -100 bias to it. layer2\n# my_weights_trainedFinal4 use this\nPground=[]\nfor i in range(100):\n    model.load_weights('my_weights.model') #load saved model weights\n    tempw = model.get_weights() \n    tempw[3][i] = -100\n    model.set_weights(tempw)\n    score = model.evaluate(x_test, y_test, verbose=0)\n    Pground.append(score[1])\n    "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "Pground = np.array(Pground)\nplt.plot(testacc - Pground)\nplt.xlabel('Neurons', fontdict=None, labelpad=None)\nplt.ylabel('Accuracy Drop', fontdict=None, labelpad=None)\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Compressed Sensing to find key neurons\nFor results in the paper, load the measurement matrix below instead of generating another random measurement matrix below."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "# mutate single neuron each time by assigning -100 bias to it.\n# my_weights_trainedFinal4 use this\nMtemp = []\nP=[]\nN=50\nfor i in range(N):\n    model.load_weights('my_weights.model') #load saved model weights\n    tempw = model.get_weights()\n    tempindex = np.random.randint(0, high=100, size=5)\n    Mtemp.append(tempindex)\n    tempw[3][tempindex] = -100\n    model.set_weights(tempw)\n    score = model.evaluate(x_test, y_test, verbose=0)\n    P.append(score[1])\n    "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "P = np.array(P)\nplt.barh(range(1,51),np.flip(testacc - P, axis=0))\nplt.ylabel('Ablations', fontdict=None, labelpad=None)\nplt.xlabel('Accuracy Drop - Group Phenotype', fontdict=None, labelpad=None)\nplt.grid()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
      ],
      "source": "# Make Measurement Matrix\n\nM = np.zeros([N,100])\nfor i in range(N):\n    M[i][Mtemp[i]] = 1.0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Load the saved Measurement Matrix in the paper"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "import pickle\n# Getting back the objects:\nwith open('../data/MeasurementMatrix_P_Pground.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n    M, P, Pground = pickle.load(f)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "#Solve LASSO\nfrom sklearn.linear_model import Lasso\n\nPnew = testacc-P\nP_infer_list = []\nL1norm=[]\nL2norm=[]\nL12tot=[]\n\nfor k in range(100):\n    alp = np.logspace(-4, -1.5, num=100)\n    clf = Lasso(alpha=alp[k])\n    clf.fit(M, Pnew)\n    P_infer = clf.coef_\n    P_infer_list.append(P_infer)\n    L1norm.append(np.sum(np.abs(P_infer)))\n    L2norm.append(np.sum((np.dot(M,P_infer)-Pnew)**2))\n    L12tot.append(L2norm[-1] + alp[k]*L1norm[-1])\n\nP_infer_array = np.asarray(P_infer_list)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "plt.plot(np.log10(alp),L2norm)\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "for k in range(100):\n    plt.plot(np.log10(alp),P_infer_array[:,k])\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "plt.imshow(M, cmap='gray')\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "Pground = np.array(Pground)\nplt.plot(range(1,101), testacc - Pground)\nplt.plot(range(1,101), -P_infer_array[40])\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Statistical Analysis of ANN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
      ],
      "source": "### ********** THIS SIMULATIONS MIGHT TAKE HOURS ********** \n### *** For results in the paper, you can load the saved results below and run further cells.\n\n# Msize=[25, 30, 35, 40, 45, 50, 55, 60]\n# Pinfer_Msize=[];\n# for k in Msize:\n#     print('---'+str(k)+'---')\n#     P_infer_temp_list=[]\n#     for j in range(0,100):\n        \n#         Mtemp = []\n#         P=[]\n#         N=k\n#         for i in range(N):\n#             model.load_weights('my_weights.model') #load saved model weights\n#             tempw = model.get_weights()\n#             tempindex = np.random.randint(0, high=100, size=np.random.randint(5,10))\n#             Mtemp.append(tempindex)\n#             tempw[3][tempindex] = -100\n#             model.set_weights(tempw)\n#             score = model.evaluate(x_test, y_test, verbose=0)\n#             P.append(score[1])\n\n#         P = np.array(P)\n#         # Make Measurement Matrix\n#         M = np.zeros([N,100])\n#         for i in range(N):\n#             M[i][Mtemp[i]] = 1.0\n\n\n#         #Solve LASSO\n#         Pnew = testacc-P\n#         clf = Lasso(alpha=0.001)\n#         clf.fit(M, Pnew)\n#         P_infer = clf.coef_\n#         P_infer_temp_list.append(P_infer)\n        \n#         print(j)\n\n\n#     P_infer_array = np.asarray(P_infer_temp_list)\n#     Pinfer_Msize.append(P_infer_array)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Load Saved Simulations"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "import pickle\n# Getting back the objects:\nwith open('../data/Pinfer_Msize.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n    Pinfer_Msize = pickle.load(f)\n    Pinfer_Msize=Pinfer_Msize[0]"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Find False Neg & Pos"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "Pground2=testacc - Pground\nPground2_top7 = deepcopy(Pground2)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "keyunits7 = np.argsort(Pground2)[-7:]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "Pground2_top7[keyunits7]=1.0\nPground2_top7[Pground2_top7!=1.0]=0."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "falseNeg_Msize=[]\nfalsePos_Msize=[]\nMsize=[25, 30, 35, 40, 45, 50, 55, 60]\n\nfor k in range(0,8):\n\n    falseNeg=[]\n    falsePos=[]\n    for i in range(100):\n        a = Pinfer_Msize[k][i,:]\n        a = np.select([a == 0., a != 0.], [np.zeros_like(a), np.ones_like(a)])\n        b = a - Pground2_top7\n        falseNeg.append(np.count_nonzero(b == -1))\n        falsePos.append(np.count_nonzero(b == 1))\n\n    falseNeg = np.asarray(falseNeg)\n    falsePos = np.asarray(falsePos)\n\n    falseNeg_Msize.append(falseNeg)\n    falsePos_Msize.append(falsePos)\n    \nfalseNeg_Msize = np.asarray(falseNeg_Msize)\nfalsePos_Msize = np.asarray(falsePos_Msize)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
      ],
      "source": "plt.errorbar(Msize,falsePos_Msize.mean(axis=1),falsePos_Msize.std(axis=1),capsize=4)\nplt.errorbar(Msize,falseNeg_Msize.mean(axis=1),falseNeg_Msize.std(axis=1),capsize=4)\nplt.ylabel('# of false neg & pos')\nplt.xlabel('# of group measurements')\nplt.legend(['False Pos', 'False Neg'])"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "### Visualize Activations"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "def get_activations(model, layer, X_batch):\n    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output])\n    activations = get_activations([X_batch,0])\n    return activations"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "y_labels = [np.argmax(y, axis=None, out=None) for y in y_test]\ny_labels = np.array(y_labels)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "x_random = np.random.rand(10000,784)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "itemindex = np.where(y_labels==0) #EDIT HERE for different digits\nitemindex = itemindex[0]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "# Get Activations\n# if you want to get activation of a single image instead of batch of images, you need to reshape it.\n# here is the explanation (https://stackoverflow.com/questions/40430186/tensorflow-valueerror-cannot-feed-value-of-shape-64-64-3-for-tensor-uplace)\n\n#test_x_for_act = test_x.reshape(1,len(test_x))\n#[101,126,136,148,157] - [4,6,19,24,27]\n\n#firing = get_activations(model, 2, x_random)\nfiring = get_activations(model, 2, x_test)\nfiring = firing[0]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
      },
      "outputs": [
      ],
      "source": "#plt.plot(np.mean(firing,axis=0))\nplt.plot(firing[472])\nplt.xlabel('Neurons', fontdict=None, labelpad=None)\nplt.ylabel('Firing Rate', fontdict=None, labelpad=None)\nplt.show()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}